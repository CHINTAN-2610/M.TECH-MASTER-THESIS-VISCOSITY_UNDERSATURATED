{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16f9fab9",
   "metadata": {},
   "source": [
    "# TITLE : MODELS OF VISCOSITY FROM COMPOSITIONAL DATA MWC7+  TEMP PRESSURE USING MACHINE LEARNING ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed97750",
   "metadata": {},
   "source": [
    "OBJECTIVE : TRINING OF MODELS FOR FUTURE SELECTION FOR PREDICTION OF VISCOSITY USING WIDE RANGE OF COMPOSITION DATA.\n",
    "\n",
    "THIS FILE AUTOMATICALLY FIT MODELS AND STORE MODELS AT GIVEN PATH \n",
    "\n",
    "IF REVIEWER WANT TO CHECK SIMILLAR MODELS USED TO PREDICT TEST OR NOT WHICH TRAINED HERE THAN IN MODEL VALIDATION FILE OPTIMIZED PARAMETER CAN BE CKECKED WHICH AVOID RETRAINING WHICH TAKE A LOT TIME AS WELL AS TO CHECK DATA TRAIN AND TEST ALREADY SEPRATED AND STAROED INTO DATASOURCE FROM PREPROCESSING FILE SAME DATA USED HERE WHICH VERIFIED BY CHEKING EXCEL FILES \n",
    "\n",
    "\n",
    "ALGORITHM APPLIED : LINEAR REGRESSION, SUPPORT VECTOR MACHINE, KNN, RANDOM FOREST, DECISION TREE, XGB , ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1540939f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-1ef187d9cf9b>:33: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "#DATA EXTRACTION, MANIPULATION, VIZULIZATION LIBRARY\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#STATISTICAL TOOLS LIBRARY\n",
    "import scipy.stats as stat\n",
    "import pylab \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "#DATA FETURES OPERATION LIBRARY\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#MODELING LIBRARY\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "#MODELLING OF DEEP LEARNING MODEL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "\n",
    "#MODEL EVALUATION LIBRARY\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_error\n",
    "\n",
    "\n",
    "#Model saving\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5bbfaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\STUDY DRIVE\\\\VISCOSITY PAPER THESIS\\\\ABOVE BUBBLE POINT\\\\VISCOSITY COMPOSITION\\\\MODEL 1\\\\DATASOURCE\\\\\"\n",
    "file_name = \"TRAIN.csv\"\n",
    "model_path = \"C:\\\\STUDY DRIVE\\\\VISCOSITY PAPER THESIS\\\\ABOVE BUBBLE POINT\\\\VISCOSITY COMPOSITION\\\\MODEL 1\\\\MODELS\\\\\"\n",
    "\n",
    "export_data_path = \"C:\\\\STUDY DRIVE\\\\VISCOSITY PAPER THESIS\\\\ABOVE BUBBLE POINT\\\\VISCOSITY COMPOSITION\\\\MODEL 1\\\\EXPORTED DATA\\\\\"\n",
    "\n",
    "figure_path = \"C:\\\\STUDY DRIVE\\\\VISCOSITY PAPER THESIS\\\\ABOVE BUBBLE POINT\\\\VISCOSITY COMPOSITION\\\\MODEL 1\\\\FIGURES\\\\\"\n",
    "\n",
    "train = pd.read_csv(path+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af82db33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H2S</th>\n",
       "      <th>N2</th>\n",
       "      <th>CO2</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7+</th>\n",
       "      <th>MWC7+</th>\n",
       "      <th>Temp</th>\n",
       "      <th>P</th>\n",
       "      <th>VISCOSITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.16330</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.06090</td>\n",
       "      <td>0.04360</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.52270</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>374.800000</td>\n",
       "      <td>137.90000</td>\n",
       "      <td>0.963000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.18062</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.088596</td>\n",
       "      <td>0.06392</td>\n",
       "      <td>0.04069</td>\n",
       "      <td>0.0259</td>\n",
       "      <td>0.52525</td>\n",
       "      <td>122.575433</td>\n",
       "      <td>323.200000</td>\n",
       "      <td>439.20458</td>\n",
       "      <td>1.660428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.40480</td>\n",
       "      <td>0.077400</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>0.05450</td>\n",
       "      <td>0.03640</td>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.31415</td>\n",
       "      <td>210.463982</td>\n",
       "      <td>370.950000</td>\n",
       "      <td>325.70000</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.20040</td>\n",
       "      <td>0.079300</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.06600</td>\n",
       "      <td>0.05870</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>0.45930</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>385.900000</td>\n",
       "      <td>137.90000</td>\n",
       "      <td>0.903000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.31890</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.04770</td>\n",
       "      <td>0.03510</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.39740</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>365.372222</td>\n",
       "      <td>124.14966</td>\n",
       "      <td>3.390000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      H2S      N2     CO2       C1        C2        C3       C4       C5  \\\n",
       "0  0.0116  0.0025  0.0219  0.16330  0.062900  0.074800  0.06090  0.04360   \n",
       "1  0.0000  0.0065  0.0086  0.18062  0.059914  0.088596  0.06392  0.04069   \n",
       "2  0.0000  0.0041  0.0044  0.40480  0.077400  0.082000  0.05450  0.03640   \n",
       "3  0.0000  0.0021  0.0034  0.20040  0.079300  0.080000  0.06600  0.05870   \n",
       "4  0.0000  0.0019  0.0251  0.31890  0.075100  0.065900  0.04770  0.03510   \n",
       "\n",
       "       C6      C7+       MWC7+        Temp          P  VISCOSITY  \n",
       "0  0.0358  0.52270  249.000000  374.800000  137.90000   0.963000  \n",
       "1  0.0259  0.52525  122.575433  323.200000  439.20458   1.660428  \n",
       "2  0.0283  0.31415  210.463982  370.950000  325.70000   0.340000  \n",
       "3  0.0508  0.45930  230.000000  385.900000  137.90000   0.903000  \n",
       "4  0.0329  0.39740  324.000000  365.372222  124.14966   3.390000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f22cc210",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(\"VISCOSITY\",axis = 1)\n",
    "y_train = train.VISCOSITY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6979354e",
   "metadata": {},
   "source": [
    "                              #### Scalling Dataset ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65eac258",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a868c421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#following model path follows for all models location\n",
    "scaler_file = 'scaler.sav'\n",
    "pickle.dump(scaler , open(model_path+scaler_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec97328",
   "metadata": {},
   "source": [
    "##### .......................................................................................SectionBreak......................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fd457a",
   "metadata": {},
   "source": [
    "## 1. Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94509d12",
   "metadata": {},
   "source": [
    "                              #### Calculate VIF for features ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da5c39f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIF = [variance_inflation_factor(x_train , i) for i in range(0,x_train.shape[1])]  #shape is indicating number of columns which is argument for VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aca55c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEATURES</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H2S</td>\n",
       "      <td>28.894730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N2</td>\n",
       "      <td>11.904725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CO2</td>\n",
       "      <td>267.575234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1</td>\n",
       "      <td>4524.728757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C2</td>\n",
       "      <td>457.926459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C3</td>\n",
       "      <td>1249.429697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C4</td>\n",
       "      <td>411.514906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C5</td>\n",
       "      <td>83.588844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C6</td>\n",
       "      <td>92.030048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C7+</td>\n",
       "      <td>7395.117043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MWC7+</td>\n",
       "      <td>2.347915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Temp</td>\n",
       "      <td>1.546351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P</td>\n",
       "      <td>1.593451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FEATURES          VIF\n",
       "0       H2S    28.894730\n",
       "1        N2    11.904725\n",
       "2       CO2   267.575234\n",
       "3        C1  4524.728757\n",
       "4        C2   457.926459\n",
       "5        C3  1249.429697\n",
       "6        C4   411.514906\n",
       "7        C5    83.588844\n",
       "8        C6    92.030048\n",
       "9       C7+  7395.117043\n",
       "10    MWC7+     2.347915\n",
       "11     Temp     1.546351\n",
       "12        P     1.593451"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VIF_DataFrame = pd.DataFrame(VIF)\n",
    "VIF_DataFrame = VIF_DataFrame.rename({0:\"VIF\"} , axis = 1)\n",
    "VIF_DataFrame[\"FEATURES\"] = X_train.columns\n",
    "VIF_DataFrame = VIF_DataFrame[[\"FEATURES\" , \"VIF\"]]\n",
    "VIF_DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f544499",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIF_DataFrame.to_excel(export_data_path+\"VIF.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d7d78",
   "metadata": {},
   "source": [
    "                              #### Model Fitting for linear regression ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a976edbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e563a",
   "metadata": {},
   "source": [
    "                         #### Model Summary #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e59072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_linear_summary = sm.add_constant(x_train, prepend=False)\n",
    "y_train_linear_summary = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93a63555",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_summary = sm.OLS(y_train_linear_summary ,  x_train_linear_summary).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "547ee538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>VISCOSITY</td>    <th>  R-squared:         </th> <td>   0.615</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.588</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   22.60</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 15 Mar 2022</td> <th>  Prob (F-statistic):</th> <td>1.40e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:00:01</td>     <th>  Log-Likelihood:    </th> <td> -95.944</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   198</td>      <th>  AIC:               </th> <td>   219.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   184</td>      <th>  BIC:               </th> <td>   265.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.3446</td> <td>    0.156</td> <td>   -2.214</td> <td> 0.028</td> <td>   -0.652</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.1113</td> <td>    0.100</td> <td>   -1.114</td> <td> 0.267</td> <td>   -0.308</td> <td>    0.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.5449</td> <td>    0.474</td> <td>   -1.150</td> <td> 0.251</td> <td>   -1.480</td> <td>    0.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -2.5141</td> <td>    1.948</td> <td>   -1.291</td> <td> 0.198</td> <td>   -6.357</td> <td>    1.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.5256</td> <td>    0.620</td> <td>   -0.848</td> <td> 0.398</td> <td>   -1.748</td> <td>    0.697</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -1.0467</td> <td>    1.024</td> <td>   -1.022</td> <td> 0.308</td> <td>   -3.066</td> <td>    0.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -1.1221</td> <td>    0.587</td> <td>   -1.910</td> <td> 0.058</td> <td>   -2.281</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.2645</td> <td>    0.265</td> <td>   -0.999</td> <td> 0.319</td> <td>   -0.787</td> <td>    0.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.4099</td> <td>    0.278</td> <td>   -1.475</td> <td> 0.142</td> <td>   -0.958</td> <td>    0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -2.7692</td> <td>    2.490</td> <td>   -1.112</td> <td> 0.268</td> <td>   -7.683</td> <td>    2.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.1597</td> <td>    0.044</td> <td>    3.599</td> <td> 0.000</td> <td>    0.072</td> <td>    0.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.2602</td> <td>    0.036</td> <td>   -7.226</td> <td> 0.000</td> <td>   -0.331</td> <td>   -0.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.0496</td> <td>    0.037</td> <td>    1.357</td> <td> 0.176</td> <td>   -0.023</td> <td>    0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.8499</td> <td>    0.029</td> <td>   29.346</td> <td> 0.000</td> <td>    0.793</td> <td>    0.907</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>46.773</td> <th>  Durbin-Watson:     </th> <td>   2.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 162.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.898</td> <th>  Prob(JB):          </th> <td>5.28e-36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.058</td> <th>  Cond. No.          </th> <td>    235.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              VISCOSITY   R-squared:                       0.615\n",
       "Model:                            OLS   Adj. R-squared:                  0.588\n",
       "Method:                 Least Squares   F-statistic:                     22.60\n",
       "Date:                Tue, 15 Mar 2022   Prob (F-statistic):           1.40e-31\n",
       "Time:                        18:00:01   Log-Likelihood:                -95.944\n",
       "No. Observations:                 198   AIC:                             219.9\n",
       "Df Residuals:                     184   BIC:                             265.9\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.3446      0.156     -2.214      0.028      -0.652      -0.037\n",
       "x2            -0.1113      0.100     -1.114      0.267      -0.308       0.086\n",
       "x3            -0.5449      0.474     -1.150      0.251      -1.480       0.390\n",
       "x4            -2.5141      1.948     -1.291      0.198      -6.357       1.329\n",
       "x5            -0.5256      0.620     -0.848      0.398      -1.748       0.697\n",
       "x6            -1.0467      1.024     -1.022      0.308      -3.066       0.973\n",
       "x7            -1.1221      0.587     -1.910      0.058      -2.281       0.037\n",
       "x8            -0.2645      0.265     -0.999      0.319      -0.787       0.258\n",
       "x9            -0.4099      0.278     -1.475      0.142      -0.958       0.138\n",
       "x10           -2.7692      2.490     -1.112      0.268      -7.683       2.144\n",
       "x11            0.1597      0.044      3.599      0.000       0.072       0.247\n",
       "x12           -0.2602      0.036     -7.226      0.000      -0.331      -0.189\n",
       "x13            0.0496      0.037      1.357      0.176      -0.023       0.122\n",
       "const          0.8499      0.029     29.346      0.000       0.793       0.907\n",
       "==============================================================================\n",
       "Omnibus:                       46.773   Durbin-Watson:                   2.182\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              162.458\n",
       "Skew:                           0.898   Prob(JB):                     5.28e-36\n",
       "Kurtosis:                       7.058   Cond. No.                         235.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_summary.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ba58d5",
   "metadata": {},
   "source": [
    "                                    #### Model Saving ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ea5db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_file = 'linear_model.sav'\n",
    "pickle.dump(linear_regression , open(model_path+linear_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23ad114",
   "metadata": {},
   "source": [
    "## 2. SVR MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10b9e79",
   "metadata": {},
   "source": [
    "                              #### Model tuning for svr Regression ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc19298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca54247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_para = {'C':np.arange(50,5000,50),'gamma':np.arange(0.01,0.5,0.01)}\n",
    "svr_grid = GridSearchCV(svr_model,svr_para, cv = 5 , verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4616eefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4851 candidates, totalling 24255 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 5648 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 12816 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 22032 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done 24255 out of 24255 | elapsed:   22.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='scale', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': array([  50,  100,  150,  200,  250,  300,  350,  400,  450,  500,  550,\n",
       "        600,  650,  700,  750,  800,  850,  900,  950, 1000, 1050, 1100,\n",
       "       1150, 1200, 1250, 1300, 1350, 1400, 1...\n",
       "       4450, 4500, 4550, 4600, 4650, 4700, 4750, 4800, 4850, 4900, 4950]),\n",
       "                         'gamma': array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 , 0.11,\n",
       "       0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21, 0.22,\n",
       "       0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32, 0.33,\n",
       "       0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43, 0.44,\n",
       "       0.45, 0.46, 0.47, 0.48, 0.49])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d18015b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 50, 'gamma': 0.060000000000000005}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e13728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_best_para = svr_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b01ed33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=50, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "    gamma=0.060000000000000005, kernel='rbf', max_iter=-1, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_regression = SVR( C = svr_best_para[\"C\"],\n",
    "                      gamma = svr_best_para[\"gamma\"])\n",
    "svr_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c806ca9",
   "metadata": {},
   "source": [
    "                                          #### Model saveing #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0510d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_file = 'svr_model.sav'\n",
    "pickle.dump(svr_regression , open(model_path+svr_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4a585c",
   "metadata": {},
   "source": [
    "## 3. Decision Tree Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8101f30b",
   "metadata": {},
   "source": [
    "                                          #### Model tuning #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "588eb01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f4011a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_para = {\n",
    "    'criterion': ['mse', 'mae'],\n",
    "    'max_depth' : range(2,32,1),\n",
    "    'min_samples_leaf' : range(1,7,1),\n",
    "    'min_samples_split': range(2,7,1),\n",
    "    'splitter' : ['best', 'random']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd9ee8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3600 candidates, totalling 18000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 17672 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 18000 out of 18000 | elapsed:   11.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse',\n",
       "                                             max_depth=None, max_features=None,\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             presort='deprecated',\n",
       "                                             random_state=None,\n",
       "                                             splitter='best'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'criterion': ['mse', 'mae'], 'max_depth': range(2, 32),\n",
       "                         'min_samples_leaf': range(1, 7),\n",
       "                         'min_samples_split': range(2, 7),\n",
       "                         'splitter': ['best', 'random']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_grid = GridSearchCV(estimator=dt_model,\n",
    "                     param_grid=dt_para,\n",
    "                     cv=5,\n",
    "                     n_jobs =-1,\n",
    "                     verbose=3)\n",
    "dt_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fb0f315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mae',\n",
       " 'max_depth': 7,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 3,\n",
       " 'splitter': 'random'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbbbc077",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_best_para = dt_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10ff71b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mae', max_depth=7,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=3,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=0, splitter='random')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_regression = DecisionTreeRegressor(criterion = dt_best_para[\"criterion\"],\n",
    "                                      max_depth = dt_best_para[\"max_depth\"],\n",
    "                                      min_samples_leaf = dt_best_para[\"min_samples_leaf\"],\n",
    "                                      min_samples_split = dt_best_para[\"min_samples_split\"],\n",
    "                                      splitter = dt_best_para[\"splitter\"],\n",
    "                                      random_state = 0\n",
    "                                      )\n",
    "\n",
    "dt_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48359c1d",
   "metadata": {},
   "source": [
    "                                          #### Model saveing #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94985ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = 'C:\\\\STUDY DRIVE\\\\Mtech New\\\\DENSITY PREDICTION\\\\MODELS\\\\SATURATION PRESSURE PREDICTION SATURATION DATASET 2 PART 4 MODELS\\\\'\n",
    "dt_file = 'dt_model.sav'\n",
    "pickle.dump(dt_regression , open(model_path+dt_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a483b4",
   "metadata": {},
   "source": [
    "## 4. Random forest Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44bf2ff",
   "metadata": {},
   "source": [
    "                                          #### Model parameter tuning #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1220c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd89700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_para = {\n",
    "    \"n_estimators\" : range(90,150,5),\n",
    "    'max_depth' : range(2,20,1),\n",
    "    'min_samples_leaf' : range(1,5,1),\n",
    "    'min_samples_split': range(2,5,1),\n",
    "    'max_features' : ['auto','log2']\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(estimator=rf_model,\n",
    "                           param_grid=rf_para,\n",
    "                           cv=5,\n",
    "                           n_jobs =-1,\n",
    "                           verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "127b0485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5184 candidates, totalling 25920 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   51.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3856 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4592 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 5392 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6256 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 8176 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 9232 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 10352 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 11536 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 14096 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 15472 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done 16912 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 18416 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 21616 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done 23312 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=-1)]: Done 25072 tasks      | elapsed: 15.3min\n",
      "[Parallel(n_jobs=-1)]: Done 25920 out of 25920 | elapsed: 15.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=None,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_depth': range(2, 20),\n",
       "                         'max_features': ['auto', 'log2'],\n",
       "                         'min_samples_leaf': range(1, 5),\n",
       "                         'min_samples_split': range(2, 5),\n",
       "                         'n_estimators': range(90, 150, 5)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ccb62c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 14,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 115}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "883a1566",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_para = rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c8648f",
   "metadata": {},
   "source": [
    "                                          #### Model fiting with tuning #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54b8ab5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=14, max_features='log2', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=115, n_jobs=None, oob_score=False,\n",
       "                      random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_regression = RandomForestRegressor(n_estimators = rf_best_para[\"n_estimators\"],\n",
    "                                      max_depth = rf_best_para[\"max_depth\"],\n",
    "                                      min_samples_leaf =rf_best_para[\"min_samples_leaf\"],\n",
    "                                      min_samples_split = rf_best_para[\"min_samples_split\"],\n",
    "                                      max_features = rf_best_para[\"max_features\"],\n",
    "                                      random_state = 0\n",
    "                                      )\n",
    "\n",
    "rf_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2435ab",
   "metadata": {},
   "source": [
    "                                          #### Model Saving #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc9c0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_file = 'rf_model.sav'\n",
    "pickle.dump(rf_regression , open(model_path+rf_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7ef5e6",
   "metadata": {},
   "source": [
    "## 5. KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90427214",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4294a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_para = {\"n_neighbors\"  : range(2,11)}\n",
    "knn_grid = GridSearchCV(knn_model,knn_para, verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c8283e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  45 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30,\n",
       "                                           metric='minkowski',\n",
       "                                           metric_params=None, n_jobs=None,\n",
       "                                           n_neighbors=5, p=2,\n",
       "                                           weights='uniform'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'n_neighbors': range(2, 11)}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=False, scoring=None, verbose=3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "786fbbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 3}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7d26ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best_para = knn_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a5cff0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_regression = KNeighborsRegressor( n_neighbors = knn_best_para[\"n_neighbors\"])\n",
    "\n",
    "knn_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d766200",
   "metadata": {},
   "source": [
    "                                          #### Model Saving #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb4419e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_file = 'knn_model.sav'\n",
    "pickle.dump(knn_regression , open(model_path+knn_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a02bc62",
   "metadata": {},
   "source": [
    "## 6. XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db23419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "15b030c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_para={\n",
    "   \n",
    "    'learning_rate': np.arange(0.1,0.2,0.04),\n",
    "    'max_depth': range(2,10,1),\n",
    "    'n_estimators':range(90,150,10),\n",
    "    \"gamma\" : np.arange(0.1,0.5,0.3),\n",
    "    \"min_child_weight\": range(1,10,2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d68cb016",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid = GridSearchCV(xgb_model,xgb_para, cv = 5 , verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5cda953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   48.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3856 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4592 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 5392 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6256 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, gamma=None,\n",
       "                                    gpu_id=None, importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estima...\n",
       "                                    reg_lambda=None, scale_pos_weight=None,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'gamma': array([0.1, 0.4]),\n",
       "                         'learning_rate': array([0.1 , 0.14, 0.18]),\n",
       "                         'max_depth': range(2, 10),\n",
       "                         'min_child_weight': range(1, 10, 2),\n",
       "                         'n_estimators': range(90, 150, 10)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "278ff28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.1,\n",
       " 'learning_rate': 0.18000000000000002,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 3,\n",
       " 'n_estimators': 90}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76929a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_para = xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9cb1d9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0.1, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.18000000000000002, max_delta_step=0, max_depth=3,\n",
       "             min_child_weight=3, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=90, n_jobs=8, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_regression = XGBRegressor(\n",
    "                    learning_rate = xgb_best_para[\"learning_rate\"],\n",
    "                    max_depth = xgb_best_para[\"max_depth\"],\n",
    "                    n_estimators = xgb_best_para[\"n_estimators\"],\n",
    "                    gamma = xgb_best_para[\"gamma\"],\n",
    "                    min_child_weight = xgb_best_para[\"min_child_weight\"]\n",
    "                    )\n",
    "xgb_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4ef0d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_file = 'xgb_model.sav'\n",
    "pickle.dump(xgb_regression , open(model_path+xgb_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc70110f",
   "metadata": {},
   "source": [
    "## 7. ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f91a2a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=x_train.shape[1]))\n",
    "    \n",
    "    for i in range(hp.Int('layers', 2, 15)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=3,\n",
    "                                            max_value=15,\n",
    "                                            step=1),\n",
    "                               activation=hp.Choice('act_' + str(i),[\"relu\",\"tanh\"])))\n",
    "        \n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mean_squared_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ff70014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_mean_squared_error',\n",
    "    max_trials=50,\n",
    "    executions_per_trial=3,\n",
    "    project_name = \"ANN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ee299d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 15, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 15, 'step': 1, 'sampling': None}\n",
      "act_0 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 15, 'step': 1, 'sampling': None}\n",
      "act_1 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f76214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c5e0a487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 14s]\n",
      "val_mean_squared_error: 0.8031985759735107\n",
      "\n",
      "Best val_mean_squared_error So Far: 0.06453858191768329\n",
      "Total elapsed time: 00h 09m 10s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train, y_train.values,\n",
    "             epochs=100,\n",
    "             validation_split = 0.20,\n",
    "             callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c1975b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\ANN\n",
      "Showing 10 best trials\n",
      "Objective(name='val_mean_squared_error', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 3\n",
      "units_0: 14\n",
      "act_0: tanh\n",
      "units_1: 12\n",
      "act_1: tanh\n",
      "learning_rate: 0.01\n",
      "units_2: 6\n",
      "act_2: tanh\n",
      "units_3: 6\n",
      "act_3: tanh\n",
      "units_4: 14\n",
      "act_4: tanh\n",
      "units_5: 12\n",
      "act_5: tanh\n",
      "units_6: 13\n",
      "act_6: tanh\n",
      "units_7: 8\n",
      "act_7: relu\n",
      "units_8: 14\n",
      "act_8: tanh\n",
      "units_9: 10\n",
      "act_9: tanh\n",
      "units_10: 12\n",
      "act_10: tanh\n",
      "units_11: 9\n",
      "act_11: tanh\n",
      "units_12: 12\n",
      "act_12: tanh\n",
      "units_13: 6\n",
      "act_13: tanh\n",
      "Score: 0.06453858191768329\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 3\n",
      "units_0: 9\n",
      "act_0: tanh\n",
      "units_1: 12\n",
      "act_1: relu\n",
      "learning_rate: 0.01\n",
      "units_2: 6\n",
      "act_2: tanh\n",
      "units_3: 14\n",
      "act_3: tanh\n",
      "units_4: 11\n",
      "act_4: tanh\n",
      "units_5: 10\n",
      "act_5: tanh\n",
      "units_6: 11\n",
      "act_6: tanh\n",
      "units_7: 6\n",
      "act_7: tanh\n",
      "units_8: 10\n",
      "act_8: relu\n",
      "units_9: 7\n",
      "act_9: tanh\n",
      "units_10: 11\n",
      "act_10: tanh\n",
      "units_11: 12\n",
      "act_11: relu\n",
      "units_12: 11\n",
      "act_12: relu\n",
      "units_13: 4\n",
      "act_13: relu\n",
      "units_14: 11\n",
      "act_14: relu\n",
      "Score: 0.06804902354876201\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 5\n",
      "units_0: 11\n",
      "act_0: tanh\n",
      "units_1: 11\n",
      "act_1: relu\n",
      "learning_rate: 0.01\n",
      "units_2: 9\n",
      "act_2: relu\n",
      "units_3: 3\n",
      "act_3: relu\n",
      "units_4: 15\n",
      "act_4: tanh\n",
      "units_5: 5\n",
      "act_5: tanh\n",
      "units_6: 11\n",
      "act_6: tanh\n",
      "units_7: 14\n",
      "act_7: relu\n",
      "units_8: 4\n",
      "act_8: relu\n",
      "units_9: 8\n",
      "act_9: relu\n",
      "units_10: 12\n",
      "act_10: relu\n",
      "units_11: 5\n",
      "act_11: relu\n",
      "units_12: 7\n",
      "act_12: relu\n",
      "units_13: 13\n",
      "act_13: tanh\n",
      "units_14: 10\n",
      "act_14: relu\n",
      "Score: 0.0689912736415863\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 8\n",
      "units_0: 9\n",
      "act_0: tanh\n",
      "units_1: 12\n",
      "act_1: tanh\n",
      "learning_rate: 0.01\n",
      "units_2: 10\n",
      "act_2: tanh\n",
      "units_3: 6\n",
      "act_3: tanh\n",
      "units_4: 14\n",
      "act_4: tanh\n",
      "units_5: 6\n",
      "act_5: tanh\n",
      "units_6: 4\n",
      "act_6: relu\n",
      "units_7: 7\n",
      "act_7: relu\n",
      "units_8: 11\n",
      "act_8: tanh\n",
      "units_9: 6\n",
      "act_9: relu\n",
      "units_10: 12\n",
      "act_10: relu\n",
      "units_11: 11\n",
      "act_11: tanh\n",
      "units_12: 14\n",
      "act_12: tanh\n",
      "units_13: 4\n",
      "act_13: tanh\n",
      "units_14: 14\n",
      "act_14: relu\n",
      "Score: 0.07045830910404523\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 5\n",
      "units_0: 6\n",
      "act_0: tanh\n",
      "units_1: 4\n",
      "act_1: tanh\n",
      "learning_rate: 0.01\n",
      "units_2: 9\n",
      "act_2: relu\n",
      "units_3: 9\n",
      "act_3: relu\n",
      "units_4: 6\n",
      "act_4: relu\n",
      "units_5: 7\n",
      "act_5: tanh\n",
      "units_6: 10\n",
      "act_6: relu\n",
      "units_7: 9\n",
      "act_7: tanh\n",
      "units_8: 5\n",
      "act_8: tanh\n",
      "units_9: 11\n",
      "act_9: relu\n",
      "units_10: 12\n",
      "act_10: relu\n",
      "units_11: 13\n",
      "act_11: tanh\n",
      "units_12: 7\n",
      "act_12: tanh\n",
      "units_13: 5\n",
      "act_13: tanh\n",
      "Score: 0.07137325654427211\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 3\n",
      "units_0: 7\n",
      "act_0: tanh\n",
      "units_1: 6\n",
      "act_1: relu\n",
      "learning_rate: 0.01\n",
      "units_2: 8\n",
      "act_2: relu\n",
      "units_3: 13\n",
      "act_3: relu\n",
      "units_4: 6\n",
      "act_4: relu\n",
      "units_5: 14\n",
      "act_5: tanh\n",
      "units_6: 4\n",
      "act_6: tanh\n",
      "units_7: 9\n",
      "act_7: relu\n",
      "units_8: 14\n",
      "act_8: tanh\n",
      "units_9: 11\n",
      "act_9: tanh\n",
      "units_10: 9\n",
      "act_10: tanh\n",
      "units_11: 5\n",
      "act_11: tanh\n",
      "units_12: 7\n",
      "act_12: relu\n",
      "units_13: 5\n",
      "act_13: tanh\n",
      "Score: 0.07142381245891254\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 11\n",
      "units_0: 8\n",
      "act_0: relu\n",
      "units_1: 5\n",
      "act_1: tanh\n",
      "learning_rate: 0.01\n",
      "units_2: 5\n",
      "act_2: relu\n",
      "units_3: 13\n",
      "act_3: relu\n",
      "units_4: 5\n",
      "act_4: relu\n",
      "units_5: 6\n",
      "act_5: relu\n",
      "units_6: 11\n",
      "act_6: relu\n",
      "units_7: 11\n",
      "act_7: tanh\n",
      "units_8: 15\n",
      "act_8: relu\n",
      "units_9: 9\n",
      "act_9: tanh\n",
      "units_10: 12\n",
      "act_10: tanh\n",
      "units_11: 3\n",
      "act_11: relu\n",
      "units_12: 14\n",
      "act_12: relu\n",
      "units_13: 12\n",
      "act_13: tanh\n",
      "Score: 0.07157580306132634\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 8\n",
      "units_0: 10\n",
      "act_0: relu\n",
      "units_1: 9\n",
      "act_1: tanh\n",
      "learning_rate: 0.01\n",
      "units_2: 4\n",
      "act_2: tanh\n",
      "units_3: 5\n",
      "act_3: tanh\n",
      "units_4: 6\n",
      "act_4: tanh\n",
      "units_5: 11\n",
      "act_5: tanh\n",
      "units_6: 5\n",
      "act_6: tanh\n",
      "units_7: 13\n",
      "act_7: relu\n",
      "units_8: 15\n",
      "act_8: tanh\n",
      "units_9: 8\n",
      "act_9: relu\n",
      "units_10: 4\n",
      "act_10: tanh\n",
      "units_11: 7\n",
      "act_11: relu\n",
      "units_12: 11\n",
      "act_12: tanh\n",
      "units_13: 9\n",
      "act_13: tanh\n",
      "Score: 0.07434874897201856\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 2\n",
      "units_0: 14\n",
      "act_0: tanh\n",
      "units_1: 4\n",
      "act_1: tanh\n",
      "learning_rate: 0.01\n",
      "units_2: 12\n",
      "act_2: relu\n",
      "units_3: 5\n",
      "act_3: tanh\n",
      "units_4: 12\n",
      "act_4: relu\n",
      "units_5: 14\n",
      "act_5: tanh\n",
      "units_6: 10\n",
      "act_6: relu\n",
      "units_7: 12\n",
      "act_7: relu\n",
      "units_8: 11\n",
      "act_8: tanh\n",
      "units_9: 8\n",
      "act_9: relu\n",
      "units_10: 5\n",
      "act_10: relu\n",
      "units_11: 11\n",
      "act_11: tanh\n",
      "units_12: 7\n",
      "act_12: relu\n",
      "units_13: 15\n",
      "act_13: relu\n",
      "units_14: 3\n",
      "act_14: relu\n",
      "Score: 0.07494914407531421\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 10\n",
      "units_0: 12\n",
      "act_0: relu\n",
      "units_1: 11\n",
      "act_1: tanh\n",
      "learning_rate: 0.001\n",
      "units_2: 12\n",
      "act_2: tanh\n",
      "units_3: 5\n",
      "act_3: relu\n",
      "units_4: 10\n",
      "act_4: relu\n",
      "units_5: 13\n",
      "act_5: tanh\n",
      "units_6: 3\n",
      "act_6: relu\n",
      "units_7: 10\n",
      "act_7: tanh\n",
      "units_8: 12\n",
      "act_8: tanh\n",
      "units_9: 13\n",
      "act_9: relu\n",
      "units_10: 6\n",
      "act_10: relu\n",
      "units_11: 14\n",
      "act_11: tanh\n",
      "units_12: 6\n",
      "act_12: relu\n",
      "units_13: 5\n",
      "act_13: relu\n",
      "units_14: 4\n",
      "act_14: tanh\n",
      "Score: 0.07928783943255742\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1e653f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 14)                196       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                180       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 78        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 461\n",
      "Trainable params: 461\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "'''This link has proved that while showing summary of result number of unit shows higher than \n",
    "    actual number of layers which reported as bug in official keras documents.\n",
    "    However it has been proven that finalized model description can be obtained by following.\n",
    "    Use number of layer shown as number_layer arguments [i.g best model with number_layer = 4\n",
    "    units_0 to units_3 in our case. Avoid higher values.]\n",
    "    \n",
    "    https://github.com/keras-team/keras-tuner/issues/66#issuecomment-525923517'''\n",
    "tuner.get_best_models()[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c50b540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_best_para = tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7686141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_regression = Sequential()\n",
    "\n",
    "\n",
    "#Input layer \n",
    "ann_regression.add(tf.keras.Input(shape=x_train.shape[1]))\n",
    "\n",
    "limit = ann_best_para[\"layers\"] \n",
    "\n",
    "#Number of hidden layer\n",
    "for i in range(0, limit) :\n",
    "    ann_regression.add(Dense(units=ann_best_para['units_'+str(i)],activation=ann_best_para['act_'+str(i)]))\n",
    "\n",
    "    \n",
    "#Last Output Layer\n",
    "ann_regression.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "\n",
    "\n",
    "#ANN compilation with loss function and optimization\n",
    "ann_regression.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=ann_best_para['learning_rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0081ec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_final = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b3bf2497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.7875 - val_loss: 0.6897\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3600 - val_loss: 0.4651\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2199 - val_loss: 0.4660\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2078 - val_loss: 0.4195\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1811 - val_loss: 0.3125\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1409 - val_loss: 0.2413\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1315 - val_loss: 0.2204\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1237 - val_loss: 0.2041\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1139 - val_loss: 0.1921\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1057 - val_loss: 0.1868\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0988 - val_loss: 0.1812\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0942 - val_loss: 0.1725\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0887 - val_loss: 0.1627\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0859 - val_loss: 0.1494\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0798 - val_loss: 0.1570\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0759 - val_loss: 0.1399\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0740 - val_loss: 0.1321\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0696 - val_loss: 0.1241\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0614 - val_loss: 0.1410\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0602 - val_loss: 0.1078\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0588 - val_loss: 0.1043\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0491 - val_loss: 0.1127\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0486 - val_loss: 0.0889\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0448 - val_loss: 0.1004\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0406 - val_loss: 0.0872\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0359 - val_loss: 0.0858\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0349 - val_loss: 0.0787\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0322 - val_loss: 0.0860\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0303 - val_loss: 0.0756\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0285 - val_loss: 0.0773\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0271 - val_loss: 0.0699\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0281 - val_loss: 0.0695\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0245 - val_loss: 0.0754\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0240 - val_loss: 0.0698\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0211 - val_loss: 0.0653\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0226 - val_loss: 0.0768\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0216 - val_loss: 0.0603\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0253 - val_loss: 0.0768\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.0638\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0212 - val_loss: 0.0799\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0191 - val_loss: 0.0612\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0195 - val_loss: 0.0682\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.0654\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0193 - val_loss: 0.0673\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0803\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0671\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.0796\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.0700\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0152 - val_loss: 0.0773\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0150 - val_loss: 0.0726\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0715\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0786\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0151 - val_loss: 0.0774\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0751\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0778\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0765\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.0802\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0843\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0795\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.0851\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0777\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0818\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0830\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0856\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0760\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0817\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0794\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0871\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.0785\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0782\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.0767\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0791\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0796\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.0786\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0784\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.0783\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0826\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.0759\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.0845\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0793\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0785\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0766\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0784\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0800\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0714\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.0740\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0861\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0726\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0896\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0765\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0757\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0771\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0720\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0811\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0692\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.0801\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.0700\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0758\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0711\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.0773\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0667\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0859\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0715\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0960\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0174 - val_loss: 0.0671\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0815\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0751\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0721\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0783\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0745\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0714\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0672\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0754\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0665\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.0723\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0691\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0724\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0647\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.007 - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0743\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0667\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0109 - val_loss: 0.0868\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0633\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.0770\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.0664\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0828\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.0640\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.0757\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0112 - val_loss: 0.0736\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0738\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.0715\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.0686\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.0800\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0696\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0795\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0065 - val_loss: 0.0680\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0799\n",
      "Epoch 00137: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24947ee0760>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_regression.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=1000,\n",
    "          validation_split=0.20, \n",
    "          verbose=1,\n",
    "          callbacks=[early_stop_final],\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "39a84960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.787482</td>\n",
       "      <td>0.689652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.359967</td>\n",
       "      <td>0.465093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.219898</td>\n",
       "      <td>0.466046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.207794</td>\n",
       "      <td>0.419460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.181105</td>\n",
       "      <td>0.312533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.012007</td>\n",
       "      <td>0.080036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.008320</td>\n",
       "      <td>0.069640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.008817</td>\n",
       "      <td>0.079509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.006482</td>\n",
       "      <td>0.067957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.007048</td>\n",
       "      <td>0.079945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  val_loss\n",
       "0    0.787482  0.689652\n",
       "1    0.359967  0.465093\n",
       "2    0.219898  0.466046\n",
       "3    0.207794  0.419460\n",
       "4    0.181105  0.312533\n",
       "..        ...       ...\n",
       "132  0.012007  0.080036\n",
       "133  0.008320  0.069640\n",
       "134  0.008817  0.079509\n",
       "135  0.006482  0.067957\n",
       "136  0.007048  0.079945\n",
       "\n",
       "[137 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ann_regression.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c66b46e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ann_regression_df = pd.DataFrame(ann_regression.history.history)\n",
    "ann_regression_df[[\"loss\",\"val_loss\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d3f7a3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 14)                196       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 12)                180       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 6)                 78        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 461\n",
      "Trainable params: 461\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann_regression.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a6b184ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 998us/step - loss: 0.0222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0221736840903759"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_regression.evaluate(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4e7cc152",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_regression_df.to_csv(export_data_path+\"LOSS_VALUES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "91f7c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_file = 'ann_model.h5'\n",
    "ann_regression.save(model_path+ann_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817f44e3",
   "metadata": {},
   "source": [
    ".......................................THE END.........................................................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2739cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c5ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
