{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16f9fab9",
   "metadata": {},
   "source": [
    "# TITLE : MODELS OF VISCOSITY FROM COMPOSITIONAL DATA MWC7+  TEMP PRESSURE USING MACHINE LEARNING ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed97750",
   "metadata": {},
   "source": [
    "OBJECTIVE : TRINING OF MODELS FOR FUTURE SELECTION FOR PREDICTION OF VISCOSITY USING WIDE RANGE OF COMPOSITION DATA.\n",
    "\n",
    "THIS FILE AUTOMATICALLY FIT MODELS AND STORE MODELS AT GIVEN PATH \n",
    "\n",
    "IF REVIEWER WANT TO CHECK SIMILLAR MODELS USED TO PREDICT TEST OR NOT WHICH TRAINED HERE THAN IN MODEL VALIDATION FILE OPTIMIZED PARAMETER CAN BE CKECKED WHICH AVOID RETRAINING WHICH TAKE A LOT TIME AS WELL AS TO CHECK DATA TRAIN AND TEST ALREADY SEPRATED AND STAROED INTO DATASOURCE FROM PREPROCESSING FILE SAME DATA USED HERE WHICH VERIFIED BY CHEKING EXCEL FILES \n",
    "\n",
    "\n",
    "ALGORITHM APPLIED : LINEAR REGRESSION, SUPPORT VECTOR MACHINE, KNN, RANDOM FOREST, DECISION TREE, XGB , ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1540939f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-1ef187d9cf9b>:33: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "#DATA EXTRACTION, MANIPULATION, VIZULIZATION LIBRARY\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#STATISTICAL TOOLS LIBRARY\n",
    "import scipy.stats as stat\n",
    "import pylab \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "#DATA FETURES OPERATION LIBRARY\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#MODELING LIBRARY\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "#MODELLING OF DEEP LEARNING MODEL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "\n",
    "#MODEL EVALUATION LIBRARY\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_error\n",
    "\n",
    "\n",
    "#Model saving\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5bbfaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\STUDY DRIVE\\\\VISCOSITY PAPER THESIS\\\\BELOW BUBBLE POINT\\\\VISCOSITY COMPOSITION\\\\MODEL 1\\\\DATASOURCE\\\\\"\n",
    "file_name = \"TRAIN.csv\"\n",
    "model_path = \"C:\\\\STUDY DRIVE\\\\VISCOSITY PAPER THESIS\\\\BELOW BUBBLE POINT\\\\VISCOSITY COMPOSITION\\\\MODEL 1\\\\MODELS\\\\\"\n",
    "\n",
    "export_data_path = \"C:\\\\STUDY DRIVE\\\\VISCOSITY PAPER THESIS\\\\BELOW BUBBLE POINT\\\\VISCOSITY COMPOSITION\\\\MODEL 1\\\\EXPORTED DATA\\\\\"\n",
    "\n",
    "figure_path = \"C:\\\\STUDY DRIVE\\\\VISCOSITY PAPER THESIS\\\\BELOW BUBBLE POINT\\\\VISCOSITY COMPOSITION\\\\MODEL 1\\\\FIGURES\\\\\"\n",
    "\n",
    "train = pd.read_csv(path+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af82db33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H2S</th>\n",
       "      <th>N2</th>\n",
       "      <th>CO2</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7+</th>\n",
       "      <th>MWC7+</th>\n",
       "      <th>Temp</th>\n",
       "      <th>P</th>\n",
       "      <th>VISCOSITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.2775</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.0311</td>\n",
       "      <td>0.4572</td>\n",
       "      <td>272.000000</td>\n",
       "      <td>364.816667</td>\n",
       "      <td>106.462585</td>\n",
       "      <td>1.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.3617</td>\n",
       "      <td>0.075732</td>\n",
       "      <td>0.078068</td>\n",
       "      <td>0.053237</td>\n",
       "      <td>0.039863</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.3335</td>\n",
       "      <td>195.711574</td>\n",
       "      <td>427.600000</td>\n",
       "      <td>123.658862</td>\n",
       "      <td>0.911174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.5773</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>92.753588</td>\n",
       "      <td>2.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.5773</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>344.250000</td>\n",
       "      <td>104.400000</td>\n",
       "      <td>2.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.2779</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.063400</td>\n",
       "      <td>0.044500</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.4670</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>364.816667</td>\n",
       "      <td>112.585034</td>\n",
       "      <td>1.860000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   H2S      N2     CO2      C1        C2        C3        C4        C5  \\\n",
       "0  0.0  0.0044  0.0083  0.2775  0.075400  0.069000  0.046100  0.031000   \n",
       "1  0.0  0.0103  0.0138  0.3617  0.075732  0.078068  0.053237  0.039863   \n",
       "2  0.0  0.0033  0.0019  0.3542  0.033600  0.009000  0.009500  0.004000   \n",
       "3  0.0  0.0033  0.0019  0.3542  0.033600  0.009000  0.009500  0.004000   \n",
       "4  0.0  0.0054  0.0050  0.2779  0.068900  0.063400  0.044500  0.032900   \n",
       "\n",
       "       C6     C7+       MWC7+        Temp           P  VISCOSITY  \n",
       "0  0.0311  0.4572  272.000000  364.816667  106.462585   1.560000  \n",
       "1  0.0338  0.3335  195.711574  427.600000  123.658862   0.911174  \n",
       "2  0.0072  0.5773  255.000000  344.000000   92.753588   2.962963  \n",
       "3  0.0072  0.5773  255.000000  344.250000  104.400000   2.650000  \n",
       "4  0.0350  0.4670  214.000000  364.816667  112.585034   1.860000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f22cc210",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(\"VISCOSITY\",axis = 1)\n",
    "y_train = train.VISCOSITY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6979354e",
   "metadata": {},
   "source": [
    "                              #### Scalling Dataset ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65eac258",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a868c421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#following model path follows for all models location\n",
    "scaler_file = 'scaler.sav'\n",
    "pickle.dump(scaler , open(model_path+scaler_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec97328",
   "metadata": {},
   "source": [
    "##### .......................................................................................SectionBreak......................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fd457a",
   "metadata": {},
   "source": [
    "## 1. Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94509d12",
   "metadata": {},
   "source": [
    "                              #### Calculate VIF for features ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da5c39f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIF = [variance_inflation_factor(x_train , i) for i in range(0,x_train.shape[1])]  #shape is indicating number of columns which is argument for VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aca55c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEATURES</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H2S</td>\n",
       "      <td>5.417068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N2</td>\n",
       "      <td>9.401669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CO2</td>\n",
       "      <td>328.200536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1</td>\n",
       "      <td>4309.523974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C2</td>\n",
       "      <td>395.684460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C3</td>\n",
       "      <td>829.874318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C4</td>\n",
       "      <td>355.192434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C5</td>\n",
       "      <td>89.743169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C6</td>\n",
       "      <td>83.480735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C7+</td>\n",
       "      <td>7879.757830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MWC7+</td>\n",
       "      <td>2.610459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Temp</td>\n",
       "      <td>1.860915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P</td>\n",
       "      <td>1.815457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FEATURES          VIF\n",
       "0       H2S     5.417068\n",
       "1        N2     9.401669\n",
       "2       CO2   328.200536\n",
       "3        C1  4309.523974\n",
       "4        C2   395.684460\n",
       "5        C3   829.874318\n",
       "6        C4   355.192434\n",
       "7        C5    89.743169\n",
       "8        C6    83.480735\n",
       "9       C7+  7879.757830\n",
       "10    MWC7+     2.610459\n",
       "11     Temp     1.860915\n",
       "12        P     1.815457"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VIF_DataFrame = pd.DataFrame(VIF)\n",
    "VIF_DataFrame = VIF_DataFrame.rename({0:\"VIF\"} , axis = 1)\n",
    "VIF_DataFrame[\"FEATURES\"] = X_train.columns\n",
    "VIF_DataFrame = VIF_DataFrame[[\"FEATURES\" , \"VIF\"]]\n",
    "VIF_DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f544499",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIF_DataFrame.to_excel(export_data_path+\"VIF.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d7d78",
   "metadata": {},
   "source": [
    "                              #### Model Fitting for linear regression ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a976edbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e563a",
   "metadata": {},
   "source": [
    "                         #### Model Summary #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e59072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_linear_summary = sm.add_constant(x_train, prepend=False)\n",
    "y_train_linear_summary = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93a63555",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_summary = sm.OLS(y_train_linear_summary ,  x_train_linear_summary).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "547ee538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>VISCOSITY</td>    <th>  R-squared:         </th> <td>   0.558</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.526</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   17.74</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 16 Mar 2022</td> <th>  Prob (F-statistic):</th> <td>4.33e-26</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:28:00</td>     <th>  Log-Likelihood:    </th> <td> -132.57</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   197</td>      <th>  AIC:               </th> <td>   293.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   183</td>      <th>  BIC:               </th> <td>   339.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.0466</td> <td>    0.082</td> <td>   -0.572</td> <td> 0.568</td> <td>   -0.208</td> <td>    0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0177</td> <td>    0.107</td> <td>   -0.165</td> <td> 0.869</td> <td>   -0.230</td> <td>    0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.5325</td> <td>    0.635</td> <td>   -0.838</td> <td> 0.403</td> <td>   -1.786</td> <td>    0.721</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -1.9242</td> <td>    2.301</td> <td>   -0.836</td> <td> 0.404</td> <td>   -6.465</td> <td>    2.617</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.2044</td> <td>    0.697</td> <td>    0.293</td> <td> 0.770</td> <td>   -1.171</td> <td>    1.580</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -1.6162</td> <td>    1.010</td> <td>   -1.600</td> <td> 0.111</td> <td>   -3.609</td> <td>    0.376</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.3083</td> <td>    0.661</td> <td>   -0.467</td> <td> 0.641</td> <td>   -1.612</td> <td>    0.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.5915</td> <td>    0.332</td> <td>   -1.781</td> <td> 0.077</td> <td>   -1.247</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.1254</td> <td>    0.320</td> <td>   -0.392</td> <td> 0.696</td> <td>   -0.757</td> <td>    0.507</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -2.1584</td> <td>    3.112</td> <td>   -0.694</td> <td> 0.489</td> <td>   -8.298</td> <td>    3.982</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.0507</td> <td>    0.057</td> <td>   -0.896</td> <td> 0.371</td> <td>   -0.163</td> <td>    0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.3167</td> <td>    0.048</td> <td>   -6.622</td> <td> 0.000</td> <td>   -0.411</td> <td>   -0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.1746</td> <td>    0.047</td> <td>   -3.697</td> <td> 0.000</td> <td>   -0.268</td> <td>   -0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.9059</td> <td>    0.035</td> <td>   25.839</td> <td> 0.000</td> <td>    0.837</td> <td>    0.975</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>70.671</td> <th>  Durbin-Watson:     </th> <td>   2.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 209.792</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.503</td> <th>  Prob(JB):          </th> <td>2.78e-46</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.065</td> <th>  Cond. No.          </th> <td>    248.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              VISCOSITY   R-squared:                       0.558\n",
       "Model:                            OLS   Adj. R-squared:                  0.526\n",
       "Method:                 Least Squares   F-statistic:                     17.74\n",
       "Date:                Wed, 16 Mar 2022   Prob (F-statistic):           4.33e-26\n",
       "Time:                        13:28:00   Log-Likelihood:                -132.57\n",
       "No. Observations:                 197   AIC:                             293.1\n",
       "Df Residuals:                     183   BIC:                             339.1\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.0466      0.082     -0.572      0.568      -0.208       0.114\n",
       "x2            -0.0177      0.107     -0.165      0.869      -0.230       0.194\n",
       "x3            -0.5325      0.635     -0.838      0.403      -1.786       0.721\n",
       "x4            -1.9242      2.301     -0.836      0.404      -6.465       2.617\n",
       "x5             0.2044      0.697      0.293      0.770      -1.171       1.580\n",
       "x6            -1.6162      1.010     -1.600      0.111      -3.609       0.376\n",
       "x7            -0.3083      0.661     -0.467      0.641      -1.612       0.995\n",
       "x8            -0.5915      0.332     -1.781      0.077      -1.247       0.064\n",
       "x9            -0.1254      0.320     -0.392      0.696      -0.757       0.507\n",
       "x10           -2.1584      3.112     -0.694      0.489      -8.298       3.982\n",
       "x11           -0.0507      0.057     -0.896      0.371      -0.163       0.061\n",
       "x12           -0.3167      0.048     -6.622      0.000      -0.411      -0.222\n",
       "x13           -0.1746      0.047     -3.697      0.000      -0.268      -0.081\n",
       "const          0.9059      0.035     25.839      0.000       0.837       0.975\n",
       "==============================================================================\n",
       "Omnibus:                       70.671   Durbin-Watson:                   2.001\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              209.792\n",
       "Skew:                           1.503   Prob(JB):                     2.78e-46\n",
       "Kurtosis:                       7.065   Cond. No.                         248.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_summary.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ba58d5",
   "metadata": {},
   "source": [
    "                                    #### Model Saving ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ea5db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_file = 'linear_model.sav'\n",
    "pickle.dump(linear_regression , open(model_path+linear_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23ad114",
   "metadata": {},
   "source": [
    "## 2. SVR MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10b9e79",
   "metadata": {},
   "source": [
    "                              #### Model tuning for svr Regression ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc19298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca54247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_para = {'C':np.arange(50,5000,50),'gamma':np.arange(0.01,0.5,0.01)}\n",
    "svr_grid = GridSearchCV(svr_model,svr_para, cv = 5 , verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4616eefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4851 candidates, totalling 24255 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 5648 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 11958 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=-1)]: Done 13712 tasks      | elapsed:   38.2s\n",
      "[Parallel(n_jobs=-1)]: Done 15824 tasks      | elapsed:   47.1s\n",
      "[Parallel(n_jobs=-1)]: Done 18320 tasks      | elapsed:   59.0s\n",
      "[Parallel(n_jobs=-1)]: Done 21200 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 24240 out of 24255 | elapsed:  1.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 24255 out of 24255 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='scale', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': array([  50,  100,  150,  200,  250,  300,  350,  400,  450,  500,  550,\n",
       "        600,  650,  700,  750,  800,  850,  900,  950, 1000, 1050, 1100,\n",
       "       1150, 1200, 1250, 1300, 1350, 1400, 1...\n",
       "       4450, 4500, 4550, 4600, 4650, 4700, 4750, 4800, 4850, 4900, 4950]),\n",
       "                         'gamma': array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 , 0.11,\n",
       "       0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21, 0.22,\n",
       "       0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32, 0.33,\n",
       "       0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43, 0.44,\n",
       "       0.45, 0.46, 0.47, 0.48, 0.49])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d18015b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 50, 'gamma': 0.05}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e13728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_best_para = svr_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b01ed33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=50, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.05,\n",
       "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_regression = SVR( C = svr_best_para[\"C\"],\n",
    "                      gamma = svr_best_para[\"gamma\"])\n",
    "svr_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c806ca9",
   "metadata": {},
   "source": [
    "                                          #### Model saveing #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0510d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_file = 'svr_model.sav'\n",
    "pickle.dump(svr_regression , open(model_path+svr_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4a585c",
   "metadata": {},
   "source": [
    "## 3. Decision Tree Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8101f30b",
   "metadata": {},
   "source": [
    "                                          #### Model tuning #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "588eb01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f4011a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_para = {\n",
    "    'criterion': ['mse', 'mae'],\n",
    "    'max_depth' : range(2,32,1),\n",
    "    'min_samples_leaf' : range(1,7,1),\n",
    "    'min_samples_split': range(2,7,1),\n",
    "    'splitter' : ['best', 'random']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd9ee8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3600 candidates, totalling 18000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 17551 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 18000 out of 18000 | elapsed:    9.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse',\n",
       "                                             max_depth=None, max_features=None,\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             presort='deprecated',\n",
       "                                             random_state=None,\n",
       "                                             splitter='best'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'criterion': ['mse', 'mae'], 'max_depth': range(2, 32),\n",
       "                         'min_samples_leaf': range(1, 7),\n",
       "                         'min_samples_split': range(2, 7),\n",
       "                         'splitter': ['best', 'random']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_grid = GridSearchCV(estimator=dt_model,\n",
    "                     param_grid=dt_para,\n",
    "                     cv=5,\n",
    "                     n_jobs =-1,\n",
    "                     verbose=3)\n",
    "dt_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fb0f315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mse',\n",
       " 'max_depth': 31,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 4,\n",
       " 'splitter': 'random'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbbbc077",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_best_para = dt_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10ff71b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=31,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=4,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=0, splitter='random')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_regression = DecisionTreeRegressor(criterion = dt_best_para[\"criterion\"],\n",
    "                                      max_depth = dt_best_para[\"max_depth\"],\n",
    "                                      min_samples_leaf = dt_best_para[\"min_samples_leaf\"],\n",
    "                                      min_samples_split = dt_best_para[\"min_samples_split\"],\n",
    "                                      splitter = dt_best_para[\"splitter\"],\n",
    "                                      random_state = 0\n",
    "                                      )\n",
    "\n",
    "dt_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48359c1d",
   "metadata": {},
   "source": [
    "                                          #### Model saveing #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94985ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = 'C:\\\\STUDY DRIVE\\\\Mtech New\\\\DENSITY PREDICTION\\\\MODELS\\\\SATURATION PRESSURE PREDICTION SATURATION DATASET 2 PART 4 MODELS\\\\'\n",
    "dt_file = 'dt_model.sav'\n",
    "pickle.dump(dt_regression , open(model_path+dt_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a483b4",
   "metadata": {},
   "source": [
    "## 4. Random forest Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44bf2ff",
   "metadata": {},
   "source": [
    "                                          #### Model parameter tuning #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1220c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd89700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_para = {\n",
    "    \"n_estimators\" : range(90,150,5),\n",
    "    'max_depth' : range(2,20,1),\n",
    "    'min_samples_leaf' : range(1,5,1),\n",
    "    'min_samples_split': range(2,5,1),\n",
    "    'max_features' : ['auto','log2']\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(estimator=rf_model,\n",
    "                           param_grid=rf_para,\n",
    "                           cv=5,\n",
    "                           n_jobs =-1,\n",
    "                           verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "127b0485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5184 candidates, totalling 25920 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   45.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2256 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3088 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4048 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5136 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6352 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 7696 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 9168 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 10768 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 12496 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 14352 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 16336 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 18448 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 20688 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 23056 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 25552 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=-1)]: Done 25920 out of 25920 | elapsed: 14.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=None,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_depth': range(2, 20),\n",
       "                         'max_features': ['auto', 'log2'],\n",
       "                         'min_samples_leaf': range(1, 5),\n",
       "                         'min_samples_split': range(2, 5),\n",
       "                         'n_estimators': range(90, 150, 5)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ccb62c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 15,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 110}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "883a1566",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_para = rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c8648f",
   "metadata": {},
   "source": [
    "                                          #### Model fiting with tuning #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54b8ab5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=15, max_features='log2', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=110, n_jobs=None, oob_score=False,\n",
       "                      random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_regression = RandomForestRegressor(n_estimators = rf_best_para[\"n_estimators\"],\n",
    "                                      max_depth = rf_best_para[\"max_depth\"],\n",
    "                                      min_samples_leaf =rf_best_para[\"min_samples_leaf\"],\n",
    "                                      min_samples_split = rf_best_para[\"min_samples_split\"],\n",
    "                                      max_features = rf_best_para[\"max_features\"],\n",
    "                                      random_state = 0\n",
    "                                      )\n",
    "\n",
    "rf_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2435ab",
   "metadata": {},
   "source": [
    "                                          #### Model Saving #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc9c0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_file = 'rf_model.sav'\n",
    "pickle.dump(rf_regression , open(model_path+rf_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7ef5e6",
   "metadata": {},
   "source": [
    "## 5. KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90427214",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4294a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_para = {\"n_neighbors\"  : range(2,11)}\n",
    "knn_grid = GridSearchCV(knn_model,knn_para, verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c8283e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  45 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30,\n",
       "                                           metric='minkowski',\n",
       "                                           metric_params=None, n_jobs=None,\n",
       "                                           n_neighbors=5, p=2,\n",
       "                                           weights='uniform'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'n_neighbors': range(2, 11)}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=False, scoring=None, verbose=3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "786fbbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 3}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7d26ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best_para = knn_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a5cff0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_regression = KNeighborsRegressor( n_neighbors = knn_best_para[\"n_neighbors\"])\n",
    "\n",
    "knn_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d766200",
   "metadata": {},
   "source": [
    "                                          #### Model Saving #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb4419e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_file = 'knn_model.sav'\n",
    "pickle.dump(knn_regression , open(model_path+knn_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a02bc62",
   "metadata": {},
   "source": [
    "## 6. XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db23419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "15b030c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_para={\n",
    "   \n",
    "    'learning_rate': np.arange(0.1,0.2,0.04),\n",
    "    'max_depth': range(2,10,1),\n",
    "    'n_estimators':range(90,150,10),\n",
    "    \"gamma\" : np.arange(0.1,0.5,0.3),\n",
    "    \"min_child_weight\": range(1,10,2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d68cb016",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid = GridSearchCV(xgb_model,xgb_para, cv = 5 , verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5cda953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:   38.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   48.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3856 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4592 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 5392 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 6256 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, gamma=None,\n",
       "                                    gpu_id=None, importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estima...\n",
       "                                    reg_lambda=None, scale_pos_weight=None,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'gamma': array([0.1, 0.4]),\n",
       "                         'learning_rate': array([0.1 , 0.14, 0.18]),\n",
       "                         'max_depth': range(2, 10),\n",
       "                         'min_child_weight': range(1, 10, 2),\n",
       "                         'n_estimators': range(90, 150, 10)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "278ff28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.1,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 9,\n",
       " 'min_child_weight': 7,\n",
       " 'n_estimators': 90}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76929a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_para = xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9cb1d9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0.1, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=9,\n",
       "             min_child_weight=7, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=90, n_jobs=8, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_regression = XGBRegressor(\n",
    "                    learning_rate = xgb_best_para[\"learning_rate\"],\n",
    "                    max_depth = xgb_best_para[\"max_depth\"],\n",
    "                    n_estimators = xgb_best_para[\"n_estimators\"],\n",
    "                    gamma = xgb_best_para[\"gamma\"],\n",
    "                    min_child_weight = xgb_best_para[\"min_child_weight\"]\n",
    "                    )\n",
    "xgb_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4ef0d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_file = 'xgb_model.sav'\n",
    "pickle.dump(xgb_regression , open(model_path+xgb_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc70110f",
   "metadata": {},
   "source": [
    "## 7. ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f91a2a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=x_train.shape[1]))\n",
    "    \n",
    "    for i in range(hp.Int('layers', 2, 15)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=3,\n",
    "                                            max_value=15,\n",
    "                                            step=1),\n",
    "                               activation=hp.Choice('act_' + str(i),[\"relu\",\"tanh\"])))\n",
    "        \n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mean_squared_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff70014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_mean_squared_error',\n",
    "    max_trials=50,\n",
    "    executions_per_trial=3,\n",
    "    project_name = \"ANN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee299d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 15, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 15, 'step': 1, 'sampling': None}\n",
      "act_0 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 15, 'step': 1, 'sampling': None}\n",
      "act_1 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f76214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c5e0a487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 12s]\n",
      "val_mean_squared_error: 0.4919435183207194\n",
      "\n",
      "Best val_mean_squared_error So Far: 0.047279808670282364\n",
      "Total elapsed time: 00h 08m 53s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train, y_train.values,\n",
    "             epochs=100,\n",
    "             validation_split = 0.20,\n",
    "             callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1975b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\ANN\n",
      "Showing 10 best trials\n",
      "Objective(name='val_mean_squared_error', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 9\n",
      "units_0: 11\n",
      "act_0: tanh\n",
      "units_1: 7\n",
      "act_1: relu\n",
      "learning_rate: 0.01\n",
      "units_2: 14\n",
      "act_2: relu\n",
      "units_3: 6\n",
      "act_3: tanh\n",
      "units_4: 6\n",
      "act_4: tanh\n",
      "units_5: 13\n",
      "act_5: relu\n",
      "units_6: 11\n",
      "act_6: relu\n",
      "units_7: 13\n",
      "act_7: relu\n",
      "units_8: 14\n",
      "act_8: tanh\n",
      "units_9: 6\n",
      "act_9: tanh\n",
      "units_10: 6\n",
      "act_10: relu\n",
      "units_11: 3\n",
      "act_11: relu\n",
      "units_12: 14\n",
      "act_12: relu\n",
      "units_13: 12\n",
      "act_13: relu\n",
      "units_14: 8\n",
      "act_14: relu\n",
      "Score: 0.047279808670282364\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 3\n",
      "units_0: 15\n",
      "act_0: relu\n",
      "units_1: 10\n",
      "act_1: relu\n",
      "learning_rate: 0.01\n",
      "units_2: 10\n",
      "act_2: tanh\n",
      "units_3: 14\n",
      "act_3: relu\n",
      "units_4: 6\n",
      "act_4: tanh\n",
      "units_5: 14\n",
      "act_5: tanh\n",
      "units_6: 10\n",
      "act_6: tanh\n",
      "units_7: 5\n",
      "act_7: relu\n",
      "units_8: 7\n",
      "act_8: relu\n",
      "units_9: 12\n",
      "act_9: relu\n",
      "units_10: 9\n",
      "act_10: relu\n",
      "units_11: 3\n",
      "act_11: relu\n",
      "units_12: 6\n",
      "act_12: relu\n",
      "units_13: 11\n",
      "act_13: relu\n",
      "units_14: 6\n",
      "act_14: tanh\n",
      "Score: 0.06051765630642573\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 12\n",
      "units_0: 10\n",
      "act_0: relu\n",
      "units_1: 14\n",
      "act_1: relu\n",
      "learning_rate: 0.001\n",
      "units_2: 8\n",
      "act_2: tanh\n",
      "units_3: 12\n",
      "act_3: tanh\n",
      "units_4: 12\n",
      "act_4: tanh\n",
      "units_5: 10\n",
      "act_5: tanh\n",
      "units_6: 14\n",
      "act_6: relu\n",
      "units_7: 5\n",
      "act_7: tanh\n",
      "units_8: 3\n",
      "act_8: relu\n",
      "units_9: 4\n",
      "act_9: tanh\n",
      "units_10: 13\n",
      "act_10: tanh\n",
      "units_11: 12\n",
      "act_11: tanh\n",
      "units_12: 12\n",
      "act_12: tanh\n",
      "units_13: 15\n",
      "act_13: tanh\n",
      "units_14: 5\n",
      "act_14: relu\n",
      "Score: 0.06954200565814972\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 14\n",
      "units_0: 7\n",
      "act_0: tanh\n",
      "units_1: 11\n",
      "act_1: tanh\n",
      "learning_rate: 0.01\n",
      "units_2: 4\n",
      "act_2: tanh\n",
      "units_3: 12\n",
      "act_3: tanh\n",
      "units_4: 11\n",
      "act_4: relu\n",
      "units_5: 7\n",
      "act_5: tanh\n",
      "units_6: 13\n",
      "act_6: relu\n",
      "units_7: 11\n",
      "act_7: relu\n",
      "units_8: 13\n",
      "act_8: tanh\n",
      "units_9: 15\n",
      "act_9: tanh\n",
      "units_10: 8\n",
      "act_10: tanh\n",
      "units_11: 14\n",
      "act_11: tanh\n",
      "units_12: 5\n",
      "act_12: tanh\n",
      "units_13: 15\n",
      "act_13: tanh\n",
      "units_14: 14\n",
      "act_14: tanh\n",
      "Score: 0.09100855390230815\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 13\n",
      "units_0: 8\n",
      "act_0: tanh\n",
      "units_1: 6\n",
      "act_1: relu\n",
      "learning_rate: 0.001\n",
      "units_2: 14\n",
      "act_2: relu\n",
      "units_3: 8\n",
      "act_3: relu\n",
      "units_4: 13\n",
      "act_4: tanh\n",
      "units_5: 6\n",
      "act_5: tanh\n",
      "units_6: 4\n",
      "act_6: tanh\n",
      "units_7: 15\n",
      "act_7: tanh\n",
      "units_8: 7\n",
      "act_8: relu\n",
      "units_9: 7\n",
      "act_9: tanh\n",
      "units_10: 4\n",
      "act_10: tanh\n",
      "units_11: 14\n",
      "act_11: relu\n",
      "units_12: 8\n",
      "act_12: tanh\n",
      "units_13: 10\n",
      "act_13: relu\n",
      "units_14: 9\n",
      "act_14: relu\n",
      "Score: 0.09166024376948674\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 5\n",
      "units_0: 15\n",
      "act_0: tanh\n",
      "units_1: 9\n",
      "act_1: relu\n",
      "learning_rate: 0.01\n",
      "units_2: 7\n",
      "act_2: relu\n",
      "units_3: 4\n",
      "act_3: relu\n",
      "units_4: 14\n",
      "act_4: relu\n",
      "units_5: 3\n",
      "act_5: relu\n",
      "units_6: 11\n",
      "act_6: relu\n",
      "units_7: 10\n",
      "act_7: relu\n",
      "units_8: 8\n",
      "act_8: relu\n",
      "units_9: 5\n",
      "act_9: relu\n",
      "units_10: 15\n",
      "act_10: tanh\n",
      "units_11: 12\n",
      "act_11: tanh\n",
      "units_12: 5\n",
      "act_12: relu\n",
      "units_13: 4\n",
      "act_13: tanh\n",
      "units_14: 8\n",
      "act_14: relu\n",
      "Score: 0.09187695135672887\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 5\n",
      "units_0: 13\n",
      "act_0: tanh\n",
      "units_1: 8\n",
      "act_1: relu\n",
      "learning_rate: 0.001\n",
      "units_2: 15\n",
      "act_2: relu\n",
      "units_3: 10\n",
      "act_3: relu\n",
      "units_4: 12\n",
      "act_4: tanh\n",
      "units_5: 10\n",
      "act_5: tanh\n",
      "units_6: 7\n",
      "act_6: relu\n",
      "units_7: 4\n",
      "act_7: relu\n",
      "units_8: 6\n",
      "act_8: relu\n",
      "units_9: 12\n",
      "act_9: tanh\n",
      "units_10: 4\n",
      "act_10: tanh\n",
      "units_11: 10\n",
      "act_11: tanh\n",
      "units_12: 11\n",
      "act_12: tanh\n",
      "units_13: 4\n",
      "act_13: tanh\n",
      "units_14: 4\n",
      "act_14: tanh\n",
      "Score: 0.09943256651361783\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 12\n",
      "units_0: 7\n",
      "act_0: tanh\n",
      "units_1: 9\n",
      "act_1: tanh\n",
      "learning_rate: 0.001\n",
      "units_2: 6\n",
      "act_2: tanh\n",
      "units_3: 13\n",
      "act_3: relu\n",
      "units_4: 15\n",
      "act_4: tanh\n",
      "units_5: 3\n",
      "act_5: relu\n",
      "units_6: 8\n",
      "act_6: relu\n",
      "units_7: 7\n",
      "act_7: tanh\n",
      "units_8: 12\n",
      "act_8: relu\n",
      "units_9: 13\n",
      "act_9: relu\n",
      "units_10: 7\n",
      "act_10: relu\n",
      "units_11: 8\n",
      "act_11: relu\n",
      "units_12: 4\n",
      "act_12: relu\n",
      "units_13: 9\n",
      "act_13: tanh\n",
      "units_14: 10\n",
      "act_14: tanh\n",
      "Score: 0.10417513300975163\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 8\n",
      "units_0: 14\n",
      "act_0: tanh\n",
      "units_1: 9\n",
      "act_1: tanh\n",
      "learning_rate: 0.001\n",
      "units_2: 7\n",
      "act_2: tanh\n",
      "units_3: 11\n",
      "act_3: relu\n",
      "units_4: 9\n",
      "act_4: tanh\n",
      "units_5: 7\n",
      "act_5: tanh\n",
      "units_6: 10\n",
      "act_6: tanh\n",
      "units_7: 9\n",
      "act_7: relu\n",
      "units_8: 6\n",
      "act_8: tanh\n",
      "units_9: 9\n",
      "act_9: tanh\n",
      "units_10: 11\n",
      "act_10: relu\n",
      "units_11: 15\n",
      "act_11: relu\n",
      "units_12: 5\n",
      "act_12: tanh\n",
      "units_13: 14\n",
      "act_13: tanh\n",
      "units_14: 11\n",
      "act_14: relu\n",
      "Score: 0.11120226234197617\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 7\n",
      "units_0: 11\n",
      "act_0: relu\n",
      "units_1: 13\n",
      "act_1: relu\n",
      "learning_rate: 0.001\n",
      "units_2: 9\n",
      "act_2: relu\n",
      "units_3: 9\n",
      "act_3: tanh\n",
      "units_4: 10\n",
      "act_4: tanh\n",
      "units_5: 3\n",
      "act_5: relu\n",
      "units_6: 8\n",
      "act_6: tanh\n",
      "units_7: 7\n",
      "act_7: tanh\n",
      "units_8: 12\n",
      "act_8: tanh\n",
      "units_9: 12\n",
      "act_9: tanh\n",
      "units_10: 5\n",
      "act_10: relu\n",
      "units_11: 10\n",
      "act_11: tanh\n",
      "units_12: 7\n",
      "act_12: relu\n",
      "units_13: 7\n",
      "act_13: tanh\n",
      "units_14: 4\n",
      "act_14: relu\n",
      "Score: 0.11488474905490875\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1e653f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 11)                154       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 84        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 14)                112       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 90        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6)                 42        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 13)                91        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 11)                154       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 13)                156       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 14)                196       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,094\n",
      "Trainable params: 1,094\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "'''This link has proved that while showing summary of result number of unit shows higher than \n",
    "    actual number of layers which reported as bug in official keras documents.\n",
    "    However it has been proven that finalized model description can be obtained by following.\n",
    "    Use number of layer shown as number_layer arguments [i.g best model with number_layer = 4\n",
    "    units_0 to units_3 in our case. Avoid higher values.]\n",
    "    \n",
    "    https://github.com/keras-team/keras-tuner/issues/66#issuecomment-525923517'''\n",
    "tuner.get_best_models()[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c50b540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_best_para = tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7686141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_regression = Sequential()\n",
    "\n",
    "\n",
    "#Input layer \n",
    "ann_regression.add(tf.keras.Input(shape=x_train.shape[1]))\n",
    "\n",
    "limit = ann_best_para[\"layers\"] \n",
    "\n",
    "#Number of hidden layer\n",
    "for i in range(0, limit) :\n",
    "    ann_regression.add(Dense(units=ann_best_para['units_'+str(i)],activation=ann_best_para['act_'+str(i)]))\n",
    "\n",
    "    \n",
    "#Last Output Layer\n",
    "ann_regression.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "\n",
    "\n",
    "#ANN compilation with loss function and optimization\n",
    "ann_regression.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=ann_best_para['learning_rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0081ec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_final = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b3bf2497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 [==============================] - 1s 35ms/step - loss: 0.9379 - val_loss: 0.5360\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4911 - val_loss: 0.3985\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3707 - val_loss: 0.3270\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2845 - val_loss: 0.2691\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2128 - val_loss: 0.2396\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1718 - val_loss: 0.2186\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1583 - val_loss: 0.2118\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1559 - val_loss: 0.1954\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1375 - val_loss: 0.1944\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1159 - val_loss: 0.2020\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1080 - val_loss: 0.2073\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1093 - val_loss: 0.1949\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1041 - val_loss: 0.2029\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0905 - val_loss: 0.1718\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0861 - val_loss: 0.1633\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0746 - val_loss: 0.1616\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0755 - val_loss: 0.1497\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0844 - val_loss: 0.1743\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0799 - val_loss: 0.1655\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0775 - val_loss: 0.1657\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0806 - val_loss: 0.1645\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0729 - val_loss: 0.1424\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0720 - val_loss: 0.1336\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0671 - val_loss: 0.1303\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0667 - val_loss: 0.1350\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0625 - val_loss: 0.1234\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0615 - val_loss: 0.1136\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0634 - val_loss: 0.1088\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0675 - val_loss: 0.1422\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0653 - val_loss: 0.1199\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0669 - val_loss: 0.1376\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0725 - val_loss: 0.1086\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0536 - val_loss: 0.1117\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0594 - val_loss: 0.1061\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0508 - val_loss: 0.1046\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0483 - val_loss: 0.0874\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0533 - val_loss: 0.1066\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0502 - val_loss: 0.1216\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0477 - val_loss: 0.1015\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0472 - val_loss: 0.1190\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0433 - val_loss: 0.1339\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0422 - val_loss: 0.1141\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0418 - val_loss: 0.0797\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0426 - val_loss: 0.1054\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0457 - val_loss: 0.1456\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0453 - val_loss: 0.0832\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0429 - val_loss: 0.0888\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0390 - val_loss: 0.1232\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0380 - val_loss: 0.1114\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0376 - val_loss: 0.0696\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0358 - val_loss: 0.0873\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0384 - val_loss: 0.0995\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0482 - val_loss: 0.0969\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0337 - val_loss: 0.0953\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0520 - val_loss: 0.0855\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0552 - val_loss: 0.1409\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0506 - val_loss: 0.0711\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0474 - val_loss: 0.0879\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0487 - val_loss: 0.0858\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0545 - val_loss: 0.0802\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0744 - val_loss: 0.1199\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0531 - val_loss: 0.1080\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0632 - val_loss: 0.1287\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0441 - val_loss: 0.0878\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0402 - val_loss: 0.0906\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0413 - val_loss: 0.0812\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0910\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0380 - val_loss: 0.0963\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0342 - val_loss: 0.1024\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0406 - val_loss: 0.1000\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0355 - val_loss: 0.0733\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0392 - val_loss: 0.0814\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0417 - val_loss: 0.0746\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0307 - val_loss: 0.0866\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0303 - val_loss: 0.1073\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0292 - val_loss: 0.0874\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0313 - val_loss: 0.0854\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0285 - val_loss: 0.1203\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0351 - val_loss: 0.1305\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0365 - val_loss: 0.1245\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0300 - val_loss: 0.1474\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0322 - val_loss: 0.0995\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0231 - val_loss: 0.1480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0315 - val_loss: 0.0834\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0284 - val_loss: 0.0825\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0343 - val_loss: 0.1297\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0456 - val_loss: 0.1037\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0363 - val_loss: 0.1349\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0349 - val_loss: 0.1141\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0301 - val_loss: 0.1063\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0247 - val_loss: 0.1094\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0220 - val_loss: 0.1204\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.1098\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0769\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0236 - val_loss: 0.0911\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0277 - val_loss: 0.1392\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0336 - val_loss: 0.1321\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0339 - val_loss: 0.1202\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0331 - val_loss: 0.0807\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0344 - val_loss: 0.0834\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0367 - val_loss: 0.1081\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0234 - val_loss: 0.1028\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0223 - val_loss: 0.1243\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.1110\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0193 - val_loss: 0.1225\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0183 - val_loss: 0.1037\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0166 - val_loss: 0.1187\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0183 - val_loss: 0.1324\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0269 - val_loss: 0.1571\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0347 - val_loss: 0.1130\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0284 - val_loss: 0.1074\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0377 - val_loss: 0.1325\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0341 - val_loss: 0.1079\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0301 - val_loss: 0.1316\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0238 - val_loss: 0.0812\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0224 - val_loss: 0.0900\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0221 - val_loss: 0.0915\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.1320\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0866\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0175 - val_loss: 0.0899\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0178 - val_loss: 0.1362\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.1071\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.1273\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0158 - val_loss: 0.1075\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.1293\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.1329\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.1328\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0161 - val_loss: 0.1265\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0340 - val_loss: 0.1564\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0328 - val_loss: 0.1121\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0267 - val_loss: 0.1122\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0195 - val_loss: 0.0745\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0206 - val_loss: 0.0774\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0162 - val_loss: 0.0630\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0223 - val_loss: 0.0804\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0296 - val_loss: 0.1325\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0353 - val_loss: 0.1020\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0211 - val_loss: 0.0790\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0191 - val_loss: 0.1188\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.0977\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0277 - val_loss: 0.0865\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0310 - val_loss: 0.0857\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0205 - val_loss: 0.0769\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.0925\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0312 - val_loss: 0.0780\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0233 - val_loss: 0.1306\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0162 - val_loss: 0.0680\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0201 - val_loss: 0.0766\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.0673\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0150 - val_loss: 0.0823\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0174 - val_loss: 0.0876\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0166 - val_loss: 0.1242\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0239 - val_loss: 0.0721\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0161 - val_loss: 0.0813\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.0825\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0770\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0840\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.1122\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0890\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0749\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0695\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0879\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.0868\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0173 - val_loss: 0.0802\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0173 - val_loss: 0.0824\n",
      "Epoch 166/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0827\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0173 - val_loss: 0.0848\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.0901\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0715\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0668\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0150 - val_loss: 0.0768\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0164 - val_loss: 0.0677\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.0733\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0735\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0765\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.0823\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.0781\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0161 - val_loss: 0.0856\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0782\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0863\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0759\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0809\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0094 - val_loss: 0.0830\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0110 - val_loss: 0.0708\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0108 - val_loss: 0.0901\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0103 - val_loss: 0.0818\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0091 - val_loss: 0.0890\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0093 - val_loss: 0.0824\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0823\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0751\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0795\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0855\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.0895\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0785\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.1227\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0226 - val_loss: 0.0854\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0200 - val_loss: 0.0910\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0212 - val_loss: 0.0780\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0165 - val_loss: 0.0783\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0750\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0761\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0783\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0081 - val_loss: 0.0764\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0086 - val_loss: 0.0770\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0779\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0070 - val_loss: 0.0896\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.1051\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.0967\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0155 - val_loss: 0.0765\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0715\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0107 - val_loss: 0.1141\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0905\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.0818\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0794\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0772\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0784\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.1196\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0909\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0818\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.0782\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.1005\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.1089\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0166 - val_loss: 0.0743\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0870\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0106 - val_loss: 0.0857\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0101 - val_loss: 0.0905\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.1033\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0911\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.1136\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0101 - val_loss: 0.1078\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.1075\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0109 - val_loss: 0.1072\n",
      "Epoch 233/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0884\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.1064\n",
      "Epoch 00234: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18e86015340>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_regression.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=1000,\n",
    "          validation_split=0.20, \n",
    "          verbose=1,\n",
    "          callbacks=[early_stop_final],\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "39a84960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.937932</td>\n",
       "      <td>0.536011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.491119</td>\n",
       "      <td>0.398465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.370700</td>\n",
       "      <td>0.327022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.284503</td>\n",
       "      <td>0.269120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.212800</td>\n",
       "      <td>0.239599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.010094</td>\n",
       "      <td>0.107770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0.008829</td>\n",
       "      <td>0.107463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0.010883</td>\n",
       "      <td>0.107192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0.012510</td>\n",
       "      <td>0.088355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.013073</td>\n",
       "      <td>0.106380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  val_loss\n",
       "0    0.937932  0.536011\n",
       "1    0.491119  0.398465\n",
       "2    0.370700  0.327022\n",
       "3    0.284503  0.269120\n",
       "4    0.212800  0.239599\n",
       "..        ...       ...\n",
       "229  0.010094  0.107770\n",
       "230  0.008829  0.107463\n",
       "231  0.010883  0.107192\n",
       "232  0.012510  0.088355\n",
       "233  0.013073  0.106380\n",
       "\n",
       "[234 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ann_regression.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c66b46e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ann_regression_df = pd.DataFrame(ann_regression.history.history)\n",
    "ann_regression_df[[\"loss\",\"val_loss\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d3f7a3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 11)                154       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 7)                 84        \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 14)                112       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 6)                 90        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 6)                 42        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 13)                91        \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 11)                154       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 13)                156       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 14)                196       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,094\n",
      "Trainable params: 1,094\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann_regression.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a6b184ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 997us/step - loss: 0.0283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.028266707435250282"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_regression.evaluate(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4e7cc152",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_regression_df.to_csv(export_data_path+\"LOSS_VALUES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "91f7c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_file = 'ann_model.h5'\n",
    "ann_regression.save(model_path+ann_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817f44e3",
   "metadata": {},
   "source": [
    ".......................................THE END.........................................................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2739cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c5ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
